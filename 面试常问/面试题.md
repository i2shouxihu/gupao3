# 金蝶账无忧：

## 1、Redis作为锁怎么实现？

## 2、分布式锁还可以怎么实现(除了Redis)？

## 3、缓存穿透、缓存击穿、缓存雪崩

## 4、Redis直接挂了：

Redis是常用的基于内存的缓存服务，能为我们缓存数据减少数据库访问从而提升性能，也能作为NoSQL数据库存储数据或借助有序队列做排队系统等。当仅作为数据缓存用时，Redis服务的可用性要求没那么高， 毕竟挂了还能从数据库获取， 但如果作为数据库或队列使用时，Redis挂了可能会影响到业务。本文整理了Redis的持久化方案，使用它们来对Redis的内存数据进行持久化，保障数据的安全性。

Redis支持RDB与AOF两种持久化机制，持久化可以避免因进程异常退出或down机导致的数据丢失问题，在下次重启时能利用之前的持久化文件实现数据恢复。

### **RDB持久化**

RDB持久化即通过创建快照（压缩的二进制文件）的方式进行持久化，保存某个时间点的全量数据。RDB持久化是Redis默认的持久化方式。RDB持久化的触发包括手动触发与自动触发两种方式。

**手动触发**

1. save， 在命令行执行save命令，将以同步的方式创建rdb文件保存快照，会阻塞服务器的主进程，生产环境中不要用
2. bgsave, 在命令行执行bgsave命令，将通过fork一个子进程以异步的方式创建rdb文件保存快照，除了fork时有阻塞，子进程在创建rdb文件时，主进程可继续处理请求

**自动触发**

1. 在redis.conf中配置 `save m n` 定时触发，如 `save 900 1`表示在900s内至少存在一次更新就触发
2. 主从复制时，如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点
3. 执行debug reload命令重新加载Redis时
4. 执行shutdown且没有开启AOF持久化

redis.conf中RDB持久化配置

```coffeescript
# 只要满足下列条件之一，则会执行bgsave命令
save 900 1 # 在900s内存在至少一次写操作
save 300 10
save 60 10000

# 禁用RBD持久化，可在最后加 save ""

# 当备份进程出错时主进程是否停止写入操作
stop-writes-on-bgsave-error yes

# 是否压缩rdb文件 推荐no 相对于硬盘成本cpu资源更贵
rdbcompression no
```

### **AOF持久化**

AOF（Append-Only-File）持久化即记录所有变更数据库状态的指令，以append的形式追加保存到AOF文件中。在服务器下次启动时，就可以通过载入和执行AOF文件中保存的命令，来还原服务器关闭前的数据库状态。

redis.conf中AOF持久化配置如下

```python
# 默认关闭AOF，若要开启将no改为yes
appendonly no

# append文件的名字
appendfilename "appendonly.aof"

# 每隔一秒将缓存区内容写入文件 默认开启的写入方式
appendfsync everysec

# 当AOF文件大小的增长率大于该配置项时自动开启重写（这里指超过原大小的100%）。
auto-aof-rewrite-percentage 100

# 当AOF文件大小大于该配置项时自动开启重写
auto-aof-rewrite-min-size 64mb
```

AOF持久化的实现包括3个步骤:

1. 命令追加：将命令追加到AOF缓冲区
2. 文件写入：缓冲区内容写到AOF文件
3. 文件保存：AOF文件保存到磁盘

其中后两步的频率通过appendfsync来配置，appendfsync的选项包括

- always， 每执行一个命令就保存一次，安全性最高，最多只丢失一个命令的数据，但是性能也最低（频繁的磁盘IO）
- everysec，每一秒保存一次，推荐使用，在安全性与性能之间折中，最多丢失一秒的数据
- no， 依赖操作系统来执行（一般大概30s一次的样子），安全性最低，性能最高，丢失操作系统最后一次对AOF文件触发SAVE操作之后的数据

AOF通过保存命令来持久化，随着时间的推移，AOF文件会越来越大，Redis通过AOF文件重写来解决AOF文件不断增大的问题（可以减少文件的磁盘占有量，加快数据恢复的速度），原理如下：

1. 调用fork，创建一个子进程
2. 子进程读取当前数据库的状态来“重写”一个新的AOF文件（这里虽然叫“重写”，但实际并没有对旧文件进行任何读取，而是根据数据库的当前状态来形成指令）
3. 主进程持续将新的变动同时写到AOF重写缓冲区与原来的AOF缓冲区中
4. 主进程获取到子进程重写AOF完成的信号，调用信号处理函数将AOF重写缓冲区内容写入新的AOF文件中，并对新文件进行重命名，原子地覆盖原有AOF文件，完成新旧文件的替换

AOF的重写也分为手动触发与自动触发

- 手动触发：直接调用bgrewriteaof命令
- 自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机。其中auto-aof-rewrite-min-size表示运行AOF重写时文件最小体积，默认为64MB。auto-aof-rewrite-percentage表示当前AOF文件大小（aof_current_size）和上一次重写后AOF文件大小（aof_base_size）的比值。自动触发时机为 aof_current_size > auto-aof-rewrite-min-size &&（aof_current_size - aof_base_size）/aof_base_size> = auto-aof-rewrite-percentage

### **RDB vs AOF**

RDB与AOF两种方式各有优缺点。

RDB的优点：与AOF相比，RDB文件相对较小，恢复数据比较快（原因见数据恢复部分）
RDB的缺点：服务器宕机，RBD方式会丢失掉上一次RDB持久化后的数据；使用bgsave fork子进程时会耗费内存。

AOF的优点：AOF只是追加文件，对服务器性能影响较小，速度比RDB快，消耗内存也少，同时可读性高。
AOF的缺点：生成的文件相对较大，即使通过AOF重写，仍然会比较大；恢复数据的速度比RDB慢。

### **数据库的恢复**

服务器启动时，如果没有开启AOF持久化功能，则会自动载入RDB文件，期间会阻塞主进程。如果开启了AOF持久化功能，服务器则会优先使用AOF文件来还原数据库状态，因为AOF文件的更新频率通常比RDB文件的更新频率高，保存的数据更完整。

redis数据库恢复的处理流程如下，

![image-20220310151049393](C:\Users\kgliu\AppData\Roaming\Typora\typora-user-images\image-20220310151049393.png)

在数据恢复方面，RDB的启动时间会更短，原因有两个：

1. RDB 文件中每一条数据只有一条记录，不会像AOF日志那样可能有一条数据的多次操作记录。所以每条数据只需要写一次就行了，文件相对较小。
2. RDB 文件的存储格式和Redis数据在内存中的编码格式是一致的，不需要再进行数据编码工作，所以在CPU消耗上要远小于AOF日志的加载。

但是在进行RDB持久化时，fork出来进行dump操作的子进程会占用与父进程一样的内存，采用的copy-on-write机制，对性能的影响和内存的消耗都是比较大的。比如16G内存，Redis已经使用了10G，这时save的话会再生成10G，变成20G，大于系统的16G。这时候会发生交换，要是虚拟内存不够则会崩溃，导致数据丢失。所以在用redis的时候一定对系统内存做好容量规划。

### **RDB、AOF混合持久化**

Redis从4.0版开始支持RDB与AOF的混合持久化方案。首先由RDB定期完成内存快照的备份，然后再由AOF完成两次RDB之间的数据备份，由这两部分共同构成持久化文件。该方案的优点是充分利用了RDB加载快、备份文件小及AOF尽可能不丢数据的特性。缺点是兼容性差，一旦开启了混合持久化，在4.0之前的版本都不识别该持久化文件，同时由于前部分是RDB格式，阅读性较低。

开启混合持久化

```rust
aof-use-rdb-preamble yes
```

数据恢复加载过程就是先按照RDB进行加载，然后把AOF命令追加写入。

### **持久化方案的建议**

1. 如果Redis只是用来做缓存服务器，比如数据库查询数据后缓存，那可以不用考虑持久化，因为缓存服务失效还能再从数据库获取恢复。
2. 如果你要想提供很高的数据保障性，那么建议你同时使用两种持久化方式。如果你可以接受灾难带来的几分钟的数据丢失，那么可以仅使用RDB。
3. 通常的设计思路是利用主从复制机制来弥补持久化时性能上的影响。即Master上RDB、AOF都不做，保证Master的读写性能，而Slave上则同时开启RDB和AOF（或4.0以上版本的混合持久化方式）来进行持久化，保证数据的安全性。

### 二者区别

*aof，rdb是两种 redis持久化的机制。用于crash后，redis的恢复。*

*rdb的特性如下：*

*Code:*

*fork一个进程，遍历hash table，利用copy on write，把整个db dump保存下来。*
*save, shutdown, slave 命令会触发这个操作。*
*粒度比较大，如果save, shutdown, slave 之前crash了，则中间的操作没办法恢复。*

*aof有如下特性：*

*Code:*

*把写操作指令，持续的写到一个类似日志文件里。（类似于从postgresql等数据库导出sql一样，只记录写操作）*
*粒度较小，crash之后，只有crash之前没有来得及做日志的操作没办法恢复。*

*两种区别就是，一个是持续的用日志记录写操作，crash后利用日志恢复；一个是平时写操作的时候不触发写，只有手动提交save命令，或者是关闭命令时，才触发备份操作。*

*选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行save的时候，再做备份（rdb）。rdb这个就更有些 eventually consistent的意思了。*

### redis的过期策略以及内存淘汰机制

redis采用的是**定期删除+惰性删除策略**。
为什么不用定时删除策略?
定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.
**定期删除+惰性删除是如何工作的呢?**
定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。
于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。
采用定期删除+惰性删除就没其他问题了么?
不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。
在redis.conf中有一行配置

```
maxmemory-policy volatile-lru
```

该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)

**volatile-lru**：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
**volatile-ttl**：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰
**volatile-random**：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰

**volatile-lfu**：最近最少频次使用

**allkeys-lfu**：最近最少频次使用

**allkeys-lru**：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
**allkeys-random**：从数据集（server.db[i].dict）中任意选择数据淘汰
**no-enviction**（驱逐）：禁止驱逐数据，新写入操作会报错

ps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。

### 如何配置Redis淘汰策略

1. 1. 找到redis.conf文件
      ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200318170108350.jpeg)
      设置Redis 内存大小的限制，我们可以设置maxmemory ，当数据达到限定大小后，会选择配置的策略淘汰数据
      比如：maxmemory 300mb。
   2. 设置内存淘汰具体使用那种策略
      ![在这里插入图片描述](https://img-blog.csdnimg.cn/20200318170150903.jpeg)

### Redis 内部结构

- dict 本质上是为了解决算法中的查找问题（Searching）是一个用于维护key和value映射关系的数据结构，与很多语言中的Map或dictionary类似。 本质上是为了解决算法中的查找问题（Searching）
- sds sds就等同于char * 它可以存储任意二进制数据，不能像C语言字符串那样以字符’\0’来标识字符串的结 束，因此它必然有个长度字段。
- skiplist （跳跃表） 跳表是一种实现起来很简单，单层多指针的链表，它查找效率很高，堪比优化过的二叉平衡树，且比平衡树的实现，
- quicklist quicklist结构在quicklist.c中的解释为A doubly linked list of ziplists意思为一个由ziplist组成的双向链表
- ziplist 压缩表 ziplist是一个编码后的列表，是由一系列特殊编码的连续内存块组成的顺序型数据结构

## 5、Rabbit如何使消息可靠？实现逻辑？

![image-20220310164258762](C:\Users\kgliu\AppData\Roaming\Typora\typora-user-images\image-20220310164258762.png)

综上：发送端重试，存到数据库，日志记录

​           Broker加入回调机制

​           消息端手动ACK

## Rabbit消费失败怎么办？

![image-20220310164605905](C:\Users\kgliu\AppData\Roaming\Typora\typora-user-images\image-20220310164605905.png)

![image-20220310164704511](C:\Users\kgliu\AppData\Roaming\Typora\typora-user-images\image-20220310164704511.png)



## RabbitMQ如何保证顺序消费

### 为什么要顺序消费

保证消息的顺序消费是生产业务场景下经常面临的挑战，例如电商的下单逻辑，在用户下单之后，会发送创建订单和扣减库存的消息，我们需要保证扣减库存在创建订单之后执行。

- 处理业务逻辑后，向MQ发送一条消息，再由消费者从 MQ 中获取 消息落盘到MySQL 中。
- 在这个过程中，可能会有增删改的操作，比如执行顺序是增加、修改、删除。
- 消费者可能换了顺序给执行成删除、修改、增加，所以我们要保证消息的顺序消费

### 为什么会不按顺序消费

对于 [RabbitMQ](https://so.csdn.net/so/search?q=RabbitMQ&spm=1001.2101.3001.7020) 来说，导致上面顺序错乱的原因通常是消费者是集群部署，不同的消费者消费到了同一订单的不同的消息。

- 如消费者1执行了增加，消费者2执行了修改，消费者C执行了删除
- 但是消费者C执行比消费者B快，消费者B又比消费者A快，就会导致消费消息的时候顺序错乱
- 本该顺序是增加、修改、删除，变成了删除、修改、增加.
  ![在这里插入图片描述](https://img-blog.csdnimg.cn/77a568c090d24eb68f041cd17126220b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16)

### 如何解决不按顺序？

RabbitMQ 的问题是由于不同的消息都发送到了同一个 queue 中，多个消费者都消费同一个 queue 的消息。

- 我们可以给 RabbitMQ 创建多个 queue，每个消费者固定消费一个 queue 的消息，
- 生产者发送消息的时候，同一个类型的消息发送到同一个 queue 中
- 由于同一个 queue 的消息是一定会保证有序的，那么同一个订单号的消息就只会被一个消费者顺序消费，从而保证了消息的顺序性。
  ![在这里插入图片描述](https://img-blog.csdnimg.cn/d8c2d643644646f9be78cf4884a828ff.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5LiA5rGf5rqq5rC0,size_20,color_FFFFFF,t_70,g_se,x_16)

## Mybatis的一级、二级缓存

1）一级缓存: 基于 PerpetualCache 的 HashMap 本地缓存，其存储作用域为 Session， 当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空，默认打开一级缓 存。

2）二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存储， 不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如 Ehcache。默 认不打开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现Serializable序列化接 口(可用来保存对象的状态),可在它的映射文件中配置 ；

3）对于缓存数据更新机制，当某一个作用域(一级缓存 Session/二级缓存Namespaces)的 进行了C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear。

## 说一下Spring的事务传播行为

spring事务的传播行为说的是，当多个事务同时存在的时候，spring如何处理这些事务的行为。

① PROPAGATION_REQUIRED：如果当前没有事务，就创建一个新事务，如果当前存在事务，就加入该事务，该设置是最常用的设置。

② PROPAGATION_SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。

③ PROPAGATION_MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。

④ PROPAGATION_REQUIRES_NEW：创建新事务，无论当前存不存在事务，都创建新事务。

⑤ PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。

⑥ PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。

⑦ PROPAGATION_NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按REQUIRED属性执行。

## MySQL事务的4大特性

## MySQL数据库的锁?行级锁的优缺点？

## MySQL性能优化？

## 什么叫索引？怎么设置索引？索引的种类？

## 唯一索引是怎么实现的？

## SQL语句的优化？

## 用自增ID好还是UUID好？

# 纷享销客：

## RabbitMQ是顺序消费还是并发消费？

RabbitMQ是怎么保证顺序的？

RabbitMQ是单机部署还是多机的？

RabbitMQ是部署一个服务还是多个服务？

队列是几个服务去消费？