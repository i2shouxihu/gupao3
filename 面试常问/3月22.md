单点登录

# RabbitMQ的消息丢失解决方案

要想保住RabbitMQ消息不丢失，需要从下面几个方面进行完善。

## 一、消息持久化

要想做到消息持久化，必须满足以下三个条件，缺一不可。

## 1、Exchange 设置持久化：durable:true

new TopicExchange("amq.topic")创建的Exchange就是持久化的。

org.springframework.amqp.core.AbstractExchange构造方法如下：

![img](https://upload-images.jianshu.io/upload_images/14311924-d62f092fe5d829be.png?imageMogr2/auto-orient/strip|imageView2/2/w/724/format/webp)

通过spring-rabbit创建Exchange

![img](https://upload-images.jianshu.io/upload_images/14311924-c8f3051a07ecd762.png?imageMogr2/auto-orient/strip|imageView2/2/w/834/format/webp)

通过RabbitMQ的web后台管理界面创建Exchange

## 2、Queue 设置持久化

new Queue(queueName)创建的Queue就是持久化的。

org.springframework.amqp.core.Queue构造方法如下：

![img](https://upload-images.jianshu.io/upload_images/14311924-b5431e215a6ef384.png?imageMogr2/auto-orient/strip|imageView2/2/w/873/format/webp)

通过spring-rabbit创建Queue

![img](https://upload-images.jianshu.io/upload_images/14311924-ef0f56a0fc5c90ec.png?imageMogr2/auto-orient/strip|imageView2/2/w/1134/format/webp)

通过 RabbitMQ的web后台管理界面创建Queue

## 3、Message持久化发送

发送消息设置发送模式deliveryMode=2代表持久化消息

org.springframework.amqp.rabbit.core.RabbitTemplate默认情况下发送模式为deliveryMode=2

org.springframework.amqp.core.MessageProperties的默认发送模式：

![img](https://upload-images.jianshu.io/upload_images/14311924-f31a57fc95701660.png?imageMogr2/auto-orient/strip|imageView2/2/w/1013/format/webp)

MessageProperties的默认发送模式

## 二、ACK确认机制

## 1、消息发送确认

ConfirmCallback 只确认消息是否正确到达 Exchange 中。

ReturnCallback 消息没有正确到达队列时触发回调，如果正确到达队列不执行。

github上面的代码：[https://github.com/wuzhong290/rabbitmq.git](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fwuzhong290%2Frabbitmq.git)

执行com.demo.message.TestReturnCallback方法testReturnCallback能够看效果。

![img](https://upload-images.jianshu.io/upload_images/14311924-39f8c068a92169fd.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

ReturnCallback 日志

## 2、消息接收确认

默认情况下消息消费者是自动 ack （确认）消息的，需要设置为手动确认，原因是：自动确认会在消息发送给消费者后立即确认，这样存在丢失消息的可能。

github上面的代码：[https://github.com/wuzhong290/rabbitmq.git](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fwuzhong290%2Frabbitmq.git)

执行com.demo.message.TestManualAcks方法testMQ能够看效果。

com.demo.message.example.NoticeHandlerACK演示了手动确认消费者的实现。

## 3、参考资料

参考https://www.jianshu.com/p/2c5eebfd0e95

上面文章的消息发送确认ReturnCallback部分需要完善一下：

return-callback="returnCallback" mandatory="true"同时设置了才有效。和rabbit:connection-factory 的publisher-returns="true"没有关系。

![img](https://upload-images.jianshu.io/upload_images/14311924-ffaa6af1abad815a.png?imageMogr2/auto-orient/strip|imageView2/2/w/891/format/webp)

![img](https://upload-images.jianshu.io/upload_images/14311924-2cd5e97887d08aca.png?imageMogr2/auto-orient/strip|imageView2/2/w/1176/format/webp)

## 三、设置集群镜像模式

参考https://www.jianshu.com/p/dd706e9ee80d 文章中的《6、HA 镜像模式队列设置》

## 四、消息补偿机制

在消息发送、接受时记录DB日志，定时轮训DB日志，查明哪些发送消息没有成功消费，启动重新发送消息机制。

# RABBITMQ解决消息幂等性问题--重复消费问题

标签： [RabbittMQ](https://www.freesion.com/tag/RabbittMQ/)

![在这里插入图片描述](https://www.freesion.com/images/262/6b54374b385e47f636f8283adc076dee.png)

1. 如果消费端 程序业务逻辑出现异常消息会消费成功吗？

- 不会成功，默认一直重试。
- rabbitmq 默认情况下 如果消费者程序出现异常的情况下，会自动实现补偿机制(重试机制）是 队列服务器 发送补偿请求，不是生产者

1. 重试实现原理：

- @RabbitListener 底层 使用Aop进行拦截，如果程序没有抛出异常，自动提交事务
- 如果Aop使用异常通知拦截 获取异常信息的话，自动实现补偿机制 ，该消息会缓存到rabbitmq服务器端进行存放，一直重试到不抛异常为为止。

1. 修改重试机制策略 ，默认是一直重试

![在这里插入图片描述](https://www.freesion.com/images/464/6568f16130a717f76c7abbc9295534a0.png)

```yaml
spring:
  rabbitmq:
  ####连接地址
    host: 127.0.0.1
   ####端口号   
    port: 5672
   ####账号 
    username: guest
   ####密码  
    password: guest
   ### 地址
    virtual-host: /admin_host
    listener:
      simple:
        retry:
        ####开启消费者（程序出现异常的情况下会）进行重试
          enabled: true
         ####最大重试次数
          max-attempts: 5
        ####重试间隔次数
          initial-interval: 3000
        ####开启手动ack  
        acknowledge-mode: manual 
```

### 消息重试机制幂等性

#### 如何合适选择重试机制

1. 情况1: 消费者获取到消息后，调用第三方接口，但接口暂时无法访问，是否需要重试? **需要重试**

```java
	 @RabbitListener(queues = "fanout_email_queue")
	 public void process(String msg) throws Exception {
	 System.out.println("邮件消费者获取生产者消息msg:" + msg);
	 JSONObject jsonObject = JSONObject.parseObject(msg);
	 String email = jsonObject.getString("email");
	 String emailUrl = "http://127.0.0.1:8083/sendEmail?email=" + email;
	 System.out.println("邮件消费者开始调用第三方邮件服务器,emailUrl:" + emailUrl);
	 JSONObject result = HttpClientUtils.httpGet(emailUrl);
	 // 如果调用第三方邮件接口无法访问，如何实现自动重试.
	 if (result == null) {
	 //抛出异常，mq会去根据配置重试
	 throw new Exception("调用第三方邮件服务器接口失败!");
	 }
	 System.out.println("邮件消费者结束调用第三方邮件服务器成功,result:" + result + "程序执行结束");

	 }
```

1. 情况2: 消费者获取到消息后，抛出数据转换异常，是否需要重试? **不需要重试**

```java
	 @RabbitListener(queues = "fanout_email_queue")
	 public void process(String msg) throws Exception {
	 System.out.println("邮件消费者获取生产者消息msg:" + msg);
	 int i= 1/0;
	 }
```

总结：对于情况2，如果消费者代码抛出异常是需要发布新版本才能解决的问题，那么不需要重试，重试也无济于事。应该采用日志记录+定时任务job健康检查+人工进行补偿

#### 消费者如果保证消息幂等性，不被重复消费

产生原因:网络延迟传输中，会造成进行MQ重试中，在重试过程中，可能会造成重复消费。

解决办法:

使用全局MessageID判断消费方使用同一个，解决幂等性。

生产端设置消息ID

消费端判断消息ID

#### 基于全局消息ID区分消息，解决幂等性

##### 生产者:

请求头设置消息id（messageId）

```java
@Component
public class FanoutProducer implements RabbitTemplate.ConfirmCallback, RabbitTemplate.ReturnCallback {
	// @Autowired
	// private AmqpTemplate amqpTemplate;
	@Autowired
	private RabbitTemplate rabbitTemplate;

	public void send(String queueName) {
		JSONObject jsonObject = new JSONObject();
		jsonObject.put("email", "644064779");
		jsonObject.put("timestamp", System.currentTimeMillis());
		String jsonString = jsonObject.toJSONString();
		System.out.println("jsonString:" + jsonString);
		// 生产者发送消息的时候需要设置消息id
		this.rabbitTemplate.setMandatory(true);
		this.rabbitTemplate.setConfirmCallback(this);
		this.rabbitTemplate.setReturnCallback(this);
		Message message = MessageBuilder.withBody(jsonString.getBytes())
				.setContentType(MessageProperties.CONTENT_TYPE_JSON).setContentEncoding("utf-8")
				.setMessageId(UUID.randomUUID() + "").build();

		rabbitTemplate.convertAndSend(queueName, message);
	}
```

##### 消费者:

###### 核心代码

```java
	// MQ重试机制需要注意的问题
	// MQ消费者幂等性问题如何解决：使用全局ID

	 @RabbitListener(queues = "fanout_email_queue")
	 public void process(Message message, @Headers Map<String, Object>
	 headers, Channel channel) throws Exception {
	 String messageId = message.getMessageProperties().getMessageId();
	 String msg = new String(message.getBody(), "UTF-8");
	 System.out.println("邮件消费者获取生产者消息msg:" + msg + ",消息id:" + messageId);
	  // 重试机制都是间隔性，没并发性问题
	{
		判断messageId的消息是否被消费成功，如果成功直接return;
	}

	 JSONObject jsonObject = JSONObject.parseObject(msg);
	 String email = jsonObject.getString("email");
	 String emailUrl = "http://127.0.0.1:8083/sendEmail?email=" + email;
	 System.out.println("邮件消费者开始调用第三方邮件服务器,emailUrl:" + emailUrl);
	 JSONObject result = HttpClientUtils.httpGet(emailUrl);
	 // 如果调用第三方邮件接口无法访问，如何实现自动重试.
	 if (result == null) {
	 throw new Exception("调用第三方邮件服务器接口失败!");
	 }
	 System.out.println("邮件消费者结束调用第三方邮件服务器成功,result:" + result + "程序执行结束");

	 }
```

###### APPLICATION.YML配置

```java
spring:
  rabbitmq:
  ####连接地址
    host: 127.0.0.1
   ####端口号   
    port: 5672
   ####账号 
    username: guest
   ####密码  
    password: guest
   ### 地址
    virtual-host: /admin_host
    listener:
      simple:
        retry:
        ####开启消费者重试
          enabled: true
         ####最大重试次数
          max-attempts: 5
        ####重试间隔次数
          initial-interval: 3000
```

## RABBITMQ签收模式(ACK)

在SpringBoot中如果没有开启手动应答，SpringBoot在AOP中进行了自动自动应答签收
开启手动应答application.yml配置

![在这里插入图片描述](https://www.freesion.com/images/538/3c5a50df6bd6a82f7df0dc7b4965a0a2.png)

![在这里插入图片描述](https://www.freesion.com/images/248/363a3413a7fe97fd8a454c3c290aa7e0.png)

```java
	 @RabbitListener(queues = "fanout_email_queue")
	 public void process(Message message, @Headers Map<String, Object>
	 headers, Channel channel) throws Exception {
	 String messageId = message.getMessageProperties().getMessageId();
	 String msg = new String(message.getBody(), "UTF-8");
	 System.out.println("邮件消费者获取生产者消息msg:" + msg + ",消息id:" + messageId);
	 // 重试机制都是间隔性

	 JSONObject jsonObject = JSONObject.parseObject(msg);
	 String email = jsonObject.getString("email");
	 String emailUrl = "http://127.0.0.1:8083/sendEmail?email=" + email;
	 System.out.println("邮件消费者开始调用第三方邮件服务器,emailUrl:" + emailUrl);
	 JSONObject result = HttpClientUtils.httpGet(emailUrl);
	 // 如果调用第三方邮件接口无法访问，如何实现自动重试.
	 if (result == null) {
	 throw new Exception("调用第三方邮件服务器接口失败!");
	 }
	 System.out.println("邮件消费者结束调用第三方邮件服务器成功,result:" + result + "程序执行结束");
	 // 手动ack
	 Long deliveryTag = (Long) headers.get(AmqpHeaders.DELIVERY_TAG);
	 // 手动签收
	 channel.basicAck(deliveryTag, false);

	 }
```

# [Nacos服务心跳和健康检查源码介绍 ](https://www.cnblogs.com/wtzbk/p/14366240.html)

### 服务心跳

Nacos Client会维护一个定时任务通过持续调用服务端的接口更新心跳时间，保证自己处于存活状态，防止服务端将服务剔除，Nacos默认5秒向服务端发送一次，通过请求服务端接口/instance/beat发送心跳。
客户端服务在注册服务的时候会增加一个心跳的任务，如下图所示:

![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203110146114-2097060231.png)
首先看下BeatInfo这个类，重点看标注的字段，该字段是给周期任务设定时间，如下图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203110403287-894301846.png)
该方法内部定义的一个DEFAULT_HEART_BEAT_INTERVAL的常量，设定5秒:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203110527557-859130093.png)
接下来我们看下addBeatInfo方法，该方法内部主要是将BeatTask任务加入到线程池ScheduledExecutorService当中，如下图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203110732574-1495415226.png)
重点部分就是看BeatTask，BeatTask继承Runnable，run方法就是我们的重点，该方法调用了NamingProxy的sendBeat方法，服务端请求地址为/instance/beat的方法
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203110917273-844386278.png)
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203111001657-634988841.png)
接下来我们把目光放到服务端，找到InstanceController的beat方法，如果是参数beat信息的话，说明是第一次发起心跳，则会带有服务实例信息，因为发起心跳成功则服务端会返回下次不要带beat信息的参数，这样客户端第二次就不会携带beat信息了。如果发现没有该服务，又没带beat信息，说明这个服务可能被移除过了，直接返回没找到。如果没有服务，但是发现有beat信息，那就从beat中获取服务实例信息，进行注册，整体执行流程如下图:

```java
@CanDistro
@PutMapping("/beat")
@Secured(parser = NamingResourceParser.class, action = ActionTypes.WRITE)
public ObjectNode beat(HttpServletRequest request) throws Exception {

ObjectNode result = JacksonUtils.createEmptyJsonNode();
//设置心跳间隔
result.put(SwitchEntry.CLIENT_BEAT_INTERVAL, switchDomain.getClientBeatInterval());

String beat = WebUtils.optional(request, "beat", StringUtils.EMPTY);
RsInfo clientBeat = null;
//判断有无心跳内容
//如果存在心跳内容则不是轻量级心跳就转化为RsInfo
if (StringUtils.isNotBlank(beat)) {
    clientBeat = JacksonUtils.toObj(beat, RsInfo.class);
}
String clusterName = WebUtils
        .optional(request, CommonParams.CLUSTER_NAME, UtilsAndCommons.DEFAULT_CLUSTER_NAME);
String ip = WebUtils.optional(request, "ip", StringUtils.EMPTY);
int port = Integer.parseInt(WebUtils.optional(request, "port", "0"));
if (clientBeat != null) {
    if (StringUtils.isNotBlank(clientBeat.getCluster())) {
        clusterName = clientBeat.getCluster();
    } else {
        // fix #2533
        clientBeat.setCluster(clusterName);
    }
    ip = clientBeat.getIp();
    port = clientBeat.getPort();
}
String namespaceId = WebUtils.optional(request, CommonParams.NAMESPACE_ID, Constants.DEFAULT_NAMESPACE_ID);
String serviceName = WebUtils.required(request, CommonParams.SERVICE_NAME);
NamingUtils.checkServiceNameFormat(serviceName);
Loggers.SRV_LOG.debug("[CLIENT-BEAT] full arguments: beat: {}, serviceName: {}", clientBeat, serviceName);
//获取实例的信息
Instance instance = serviceManager.getInstance(namespaceId, serviceName, clusterName, ip, port);
//如果实例不存在
if (instance == null) {
    if (clientBeat == null) {
        result.put(CommonParams.CODE, NamingResponseCode.RESOURCE_NOT_FOUND);
        return result;
    }

​    Loggers.SRV_LOG.warn("[CLIENT-BEAT] The instance has been removed for health mechanism, "

   + "perform data compensation operations, beat: {}, serviceName: {}", clientBeat, serviceName);
     容创建一个实例信息
         instance = new Instance();
         instance.setPort(clientBeat.getPort());
         instance.setIp(clientBeat.getIp());
         instance.setWeight(clientBeat.getWeight());
         instance.setMetadata(clientBeat.getMetadata());
         instance.setClusterName(clusterName);
         instance.setServiceName(serviceName);
         instance.setInstanceId(instance.getInstanceId());
         instance.setEphemeral(clientBeat.isEphemeral());
         //注册实例
         serviceManager.registerInstance(namespaceId, serviceName, instance);
     }
     //获取服务的信息
     Service service = serviceManager.getService(namespaceId, serviceName);

if (service == null) {
    throw new NacosException(NacosException.SERVER_ERROR,
            "service not found: " + serviceName + "@" + namespaceId);
}
//不存在的话，要创建一个进行处理
if (clientBeat == null) {
    clientBeat = new RsInfo();
    clientBeat.setIp(ip);
    clientBeat.setPort(port);
    clientBeat.setCluster(clusterName);
}
//开启心跳检查任务
service.processClientBeat(clientBeat);

result.put(CommonParams.CODE, NamingResponseCode.OK);
//5秒间隔
if (instance.containsMetadata(PreservedMetadataKeys.HEART_BEAT_INTERVAL)) {
    result.put(SwitchEntry.CLIENT_BEAT_INTERVAL, instance.getInstanceHeartBeatInterval());
}
//告诉客户端不需要带上心跳信息了，变成轻量级心跳了
result.put(SwitchEntry.LIGHT_BEAT_ENABLED, switchDomain.isLightBeatEnabled());
return result;

}
```

接下来我们看一下processClientBeat方法，该方法将ClientBeatProcessor放入到线程池中，接下来我们看下重点看下run方法,

![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203111337939-780296120.png)
该方法内部主要就是更新对应实例下心跳时间，整体上如下图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203111511141-903787977.png)
至此完成了从客户端到服务端更新实例的心跳时间，下图是整体的时序图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203111725972-961856416.png)

### 服务的健康检查

Nacos Server会开启一个定时任务来检查注册服务的健康情况，对于超过15秒没收到客户端的心跳实例会将它的 healthy属性置为false，此时当客户端不会将该实例的信息发现，如果某个服务的实例超过30秒没收到心跳，则剔除该实例，如果剔除的实例恢复，发送心跳则会恢复。
当有实例注册的时候，我们会看到有个service.init()的方法，该方法的实现主要是将ClientBeatCheckTask加入到线程池当中，如下图:

![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203113625578-2011349034.png)
ClientBeatCheckTask中的run方法主要做两件事心跳时间超过15秒则设置该实例信息为不健康状况和心跳时间超过30秒则删除该实例信息，如下代码:

```java

public void run() {
    try {
        if (!getDistroMapper().responsible(service.getName())) {
            return;
        }
 
        if (!getSwitchDomain().isHealthCheckEnabled()) {
            return;
        }
        //获取服务所有实例信息
        List<Instance> instances = service.allIPs(true);
 
        // first set health status of instances:
        for (Instance instance : instances) {
            //如果心跳时间超过15秒则设置该实例信息为不健康状况
            if (System.currentTimeMillis() - instance.getLastBeat() > instance.getInstanceHeartBeatTimeOut()) {
                if (!instance.isMarked()) {
                    if (instance.isHealthy()) {
                        instance.setHealthy(false);
                        Loggers.EVT_LOG
                                .info("{POS} {IP-DISABLED} valid: {}:{}@{}@{}, region: {}, msg: client timeout after {}, last beat: {}",
                                        instance.getIp(), instance.getPort(), instance.getClusterName(),
                                        service.getName(), UtilsAndCommons.LOCALHOST_SITE,
                                        instance.getInstanceHeartBeatTimeOut(), instance.getLastBeat());
                        getPushService().serviceChanged(service);
                        ApplicationUtils.publishEvent(new InstanceHeartbeatTimeoutEvent(this, instance));
                    }
                }
            }
        }
 
        if (!getGlobalConfig().isExpireInstance()) {
            return;
        }
 
        // then remove obsolete instances:
        for (Instance instance : instances) {
 
            if (instance.isMarked()) {
                continue;
            }
            //如果心跳时间超过30秒则删除该实例信息
            if (System.currentTimeMillis() - instance.getLastBeat() > instance.getIpDeleteTimeout()) {
                // delete instance
                Loggers.SRV_LOG.info("[AUTO-DELETE-IP] service: {}, ip: {}", service.getName(),
                        JacksonUtils.toJson(instance));
                deleteIp(instance);
            }
        }
 
    } catch (Exception e) {
        Loggers.SRV_LOG.warn("Exception while processing client beat time out.", e);
    }
 
}
```



首先我们来看一下deleteIp方法，该方法内部主要通过构建删除请求，发送删除请求，如下图:

![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203113847929-1505177188.png)
删除实例的接口如下图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203114100774-1998085533.png)
内部通过调用ServiceManager的removeInstance方法，如下图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203114232082-1392434867.png)
重点看下substractIpAddresses内部通过调用updateIpAddresses，该方法内部主要就是移除到超过30秒的实例信息，如下图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203114459723-1111599452.png)
到此完成删除实例的过程，整体的时序图如下:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203114634106-2130560652.png)
接下来我们看标记不健康时候的代码，这部分代码在客户端注册的时候也出现相同的代码，只是我们略过了，这部分也是观察者模式的重要体现，从这里我们可以学习到的东西在于结合Spring的事件机制，轻松实现观察者模式，当然这个里面也有部分我感觉写的不太好，哈哈，大佬们看到勿喷。
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203114800616-680974236.png)
首先我们看serviceChanged方法，该方法主要是发布一个服务不健康的事件，如下图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203115054572-1717093596.png)
接下来我们看下如何处理这个事件，这个时候涉及PushService这个类，整体的继承结构如下图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203115203034-1847618815.png)
我们看到该类的继承ApplicationListener接口，该接口是一个支持泛型的接口，传入了ServiceChangeEvent的类，此处就是对事件的处理，如下图:
![img](https://img2020.cnblogs.com/blog/1005447/202102/1005447-20210203115322522-2142129798.png)
接下来看一下onApplicationEvent方法，这个方法主要完成了准备数据，发送数据这几件事情:

```java
public void onApplicationEvent(ServiceChangeEvent event) {
    Service service = event.getService();
    String serviceName = service.getName();
    String namespaceId = service.getNamespaceId();
 
    Future future = GlobalExecutor.scheduleUdpSender(() -> {
        try {
            Loggers.PUSH.info(serviceName + " is changed, add it to push queue.");
            //获取所有需要推送的客户端
            ConcurrentMap<String, PushClient> clients = clientMap
                    .get(UtilsAndCommons.assembleFullServiceName(namespaceId, serviceName));
            if (MapUtils.isEmpty(clients)) {
                return;
            }
 
            Map<String, Object> cache = new HashMap<>(16);
            long lastRefTime = System.nanoTime();
            for (PushClient client : clients.values()) {
                //超时的不删除跳过处理
                if (client.zombie()) {
                    Loggers.PUSH.debug("client is zombie: " + client.toString());
                    clients.remove(client.toString());
                    Loggers.PUSH.debug("client is zombie: " + client.toString());
                    continue;
                }
 
                Receiver.AckEntry ackEntry;
                Loggers.PUSH.debug("push serviceName: {} to client: {}", serviceName, client.toString());
                String key = getPushCacheKey(serviceName, client.getIp(), client.getAgent());
                byte[] compressData = null;
                Map<String, Object> data = null;
 
                if (switchDomain.getDefaultPushCacheMillis() >= 20000 && cache.containsKey(key)) {
                    org.javatuples.Pair pair = (org.javatuples.Pair) cache.get(key);
                    compressData = (byte[]) (pair.getValue0());
                    data = (Map<String, Object>) pair.getValue1();
                    Loggers.PUSH.debug("[PUSH-CACHE] cache hit: {}:{}", serviceName, client.getAddrStr());
                }
                //准备UDP数据
                if (compressData != null) {
                    ackEntry = prepareAckEntry(client, compressData, data, lastRefTime);
                } else {
                    ackEntry = prepareAckEntry(client, prepareHostsData(client), lastRefTime);
                    if (ackEntry != null) {
                        cache.put(key, new org.javatuples.Pair<>(ackEntry.origin.getData(), ackEntry.data));
                    }
                }
 
                Loggers.PUSH.info("serviceName: {} changed, schedule push for: {}, agent: {}, key: {}",
                        client.getServiceName(), client.getAddrStr(), client.getAgent(),
                        (ackEntry == null ? null : ackEntry.key));
                //发送数据
                udpPush(ackEntry);
            }
        } catch (Exception e) {
            Loggers.PUSH.error("[NACOS-PUSH] failed to push serviceName: {} to client, error: {}", serviceName, e);
 
        } finally {
            //发送完成删除
            futureMap.remove(UtilsAndCommons.assembleFullServiceName(namespaceId, serviceName));
        }
 
    }, 1000, TimeUnit.MILLISECONDS);
    //增加待推送的任务
    futureMap.put(UtilsAndCommons.assembleFullServiceName(namespaceId, serviceName), future);
 
}
```

接下里我们重点看下udpPush的方法，整个方法主要是通过一个Map对象来记录UDP请求，如果没收到就重试发送请求，整体如下:

```java
private static Receiver.AckEntry udpPush(Receiver.AckEntry ackEntry) {
    if (ackEntry == null) {
        Loggers.PUSH.error("[NACOS-PUSH] ackEntry is null.");
        return null;
    }
 
    //如果大于最大的尝试次数
    //移除发送的数据和待确认的key
    //失败推送的次数+1
    if (ackEntry.getRetryTimes() > MAX_RETRY_TIMES) {
        Loggers.PUSH.warn("max re-push times reached, retry times {}, key: {}", ackEntry.retryTimes, ackEntry.key);
        ackMap.remove(ackEntry.key);
        udpSendTimeMap.remove(ackEntry.key);
        failedPush += 1;
        return ackEntry;
    }
 
    try {
        if (!ackMap.containsKey(ackEntry.key)) {
            totalPush++;
        }
        //记录UDP请求的返回信息
        ackMap.put(ackEntry.key, ackEntry);
        udpSendTimeMap.put(ackEntry.key, System.currentTimeMillis());
 
        Loggers.PUSH.info("send udp packet: " + ackEntry.key);
        //发送UDP请求
        udpSocket.send(ackEntry.origin);
 
        ackEntry.increaseRetryTime();
        //如果UDP没收到返回信息 每10秒尝试一下
        GlobalExecutor.scheduleRetransmitter(new Retransmitter(ackEntry),
                TimeUnit.NANOSECONDS.toMillis(ACK_TIMEOUT_NANOS), TimeUnit.MILLISECONDS);
 
        return ackEntry;
    } catch (Exception e) {
        Loggers.PUSH.error("[NACOS-PUSH] failed to push data: {} to client: {}, error: {}", ackEntry.data,
                ackEntry.origin.getAddress().getHostAddress(), e);
        ackMap.remove(ackEntry.key);
        udpSendTimeMap.remove(ackEntry.key);
        failedPush += 1;
 
        return null;
    }
}
```

服务端有发送，那么客户端就有接收的，接收部分我理解上是服务发现部分，这里我们就不做过多介绍，待下一篇再来聊聊。



# Nacos配置中心交互模型是 push 还是 pull ？你应该这么回答

对于`Nacos`大家应该都不太陌生，出身阿里名声在外，能做动态服务发现、配置管理，非常好用的一个工具。然而这样的技术用的人越多面试被问的概率也就越大，如果只停留在使用层面，那面试可能要吃大亏。

比如我们今天要讨论的话题，`Nacos`在做配置中心的时候，配置数据的交互模式是服务端推过来还是客户端主动拉的？

![img](https://img-blog.csdnimg.cn/20210604073705295.png)

这里我先抛出答案：客户端主动拉的！

接下来咱们扒一扒`Nacos`的源码，来看看它具体是如何实现的？

### 配置中心

聊`Nacos`之前简单回顾下配置中心的由来。

简单理解配置中心的作用就是对配置统一管理，修改配置后应用可以动态感知，而无需重启。

因为在传统项目中，大多都采用静态配置的方式，也就是把配置信息都写在应用内的`yml`或`properties`这类文件中，如果要想修改某个配置，通常要重启应用才可以生效。

但有些场景下，比如我们想要在应用运行时，通过修改某个配置项，实时的控制某一个功能的开闭，频繁的重启应用肯定是不能接受的。

尤其是在微服务架构下，我们的应用服务拆分的粒度很细，少则几十多则上百个服务，每个服务都会有一些自己特有或通用的配置。假如此时要改变通用配置，难道要我挨个改几百个服务配置？很显然这不可能。所以为了解决此类问题配置中心应运而生。

![配置中心](https://img-blog.csdnimg.cn/202106102227286.png?)

### 推与拉模型

客户端与配置中心的数据交互方式其实无非就两种，要么推`push`，要么拉`pull`。

**推模型**

客户端与服务端建立`TCP`长连接，当服务端配置数据有变动，立刻通过建立的长连接将数据推送给客户端。

优势：长链接的优点是实时性，一旦数据变动，立即推送变更数据给客户端，而且对于客户端而言，这种方式更为简单，只建立连接接收数据，并不需要关心是否有数据变更这类逻辑的处理。

弊端：长连接可能会因为网络问题，导致不可用，也就是俗称的`假死`。连接状态正常，但实际上已无法通信，所以要有的心跳机制`KeepAlive`来保证连接的可用性，才可以保证配置数据的成功推送。

**拉模型**

客户端主动的向服务端发请求拉配置数据，常见的方式就是轮询，比如每3s向服务端请求一次配置数据。

轮询的优点是实现比较简单。但弊端也显而易见，轮询无法保证数据的实时性，什么时候请求？间隔多长时间请求一次？都是不得不考虑的问题，而且轮询方式对服务端还会产生不小的压力。

### 长轮询

开篇我们就给出了答案，`nacos`采用的是客户端主动拉`pull`模型，应用长轮询（`Long Polling`）的方式来获取配置数据。

额？以前只听过轮询，长轮询又是什么鬼？它和传统意义上的轮询（暂且叫短轮询吧，方便比较）有什么不同呢？

**短轮询**

不管服务端配置数据是否有变化，不停的发起请求获取配置，比如支付场景中前段JS轮询订单支付状态。

这样的坏处显而易见，由于配置数据并不会频繁变更，若是一直发请求，势必会对服务端造成很大压力。还会造成推送数据的延迟，比如：每10s请求一次配置，如果在第11s时配置更新了，那么推送将会延迟9s，等待下一次请求。

![img](https://img-blog.csdnimg.cn/2021061010185363.png)

为了解决短轮询的问题，有了长轮询方案。

**长轮询**

长轮询可不是什么新技术，它不过是由服务端控制响应客户端请求的返回时间，来减少客户端无效请求的一种优化手段，其实对于客户端来说与短轮询的使用并没有本质上的区别。

客户端发起请求后，服务端不会立即返回请求结果，而是将请求挂起等待一段时间，如果此段时间内服务端数据变更，立即响应客户端请求，若是一直无变化则等到指定的超时时间后响应请求，客户端重新发起长链接。

![img](https://img-blog.csdnimg.cn/20210610101939816.png)